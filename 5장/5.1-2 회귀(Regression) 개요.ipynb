{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45546173",
   "metadata": {},
   "source": [
    "# 1. 회귀(Regression)\n",
    "\n",
    "> **회귀(Regression)란**\n",
    " - 데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을 이용햔 통계학 기법\n",
    " - 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법\n",
    " - 머신러닝 회귀 예측의 핵심은 주어진 피처와 결정값 데이터 기반에서 학습을 통해 최적의 회귀 계수를 찾아내는 것\n",
    " \n",
    "> **회귀의 유형**\n",
    " - 회귀 계수의 선형/비선형 여부, 독립변수의 개수, 종속변수의 개수에 따라 여러 유형으로 나누어짐\n",
    "|독립변수 개수|회귀 계수의 결합|\n",
    "|:---:|:---:|\n",
    "|1개(단일 회귀)|선형(서형 회귀)|\n",
    "|여러 개(다중 회귀)|비선형(비선형 회귀)|\n",
    "\n",
    "> **지도 학습의 유형**\n",
    " - 1) 분류(Classification) : 예측값이 카테고리와 같은 이산형 클래스 값\n",
    " - 2) 회귀(Regression) : 연속형 숫자 값(연속값)\n",
    " ![](./회귀_지도학습종류1.png)\n",
    " ![](./회귀_지도학습종류2.png)\n",
    " \n",
    "> **선형회귀의 종류**\n",
    "\n",
    "여러 가지 회귀 중에서 선형 회귀가 가장 많이 사용되며, 과적합 문제 해결을 위한 회귀 계수에 규제 적용 방법은 아래와 같이 구분 가능\n",
    "- 일반 선형 회귀 : 예측값과 실제 값의 RSS(Residual Sum of Squares)를 최소화할 수 있도록 회귀 계수를 최적화하며. 규제(Regularization)를 적용하지 않은 모델\n",
    "- 릿지(Ridge) : 릿지 회귀는 선형 회귀에 L2 규제를 추가한 회귀 모델, L2 규제는 상대적으로 큰 회귀 계수 갑스이 예측 영향도를 감소시키기 위해 회귀 계수값을 더 작게 만드는 규제 모델\n",
    "- 엘라스틱넷(ElasticNet) : L2, L1규제를 함께 결합한 모델로 주로 피처가 많은 데이터 셋에 적용되며 L1규제로 피처의 개수를 줄임과 동시에 L2 규제로 계수 값의 크기 조정\n",
    "- 로지스틱 회귀(Logistic Regression): 분류에 사용되는 선형 모델로 일반적으로 이진 분류 뿐만 아니라 최소 영역의 분류로 텍스트 분류와 같은 영역에서 뛰어난 예측 성능 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95af563",
   "metadata": {},
   "source": [
    "# 2. 단순 선형 회귀를 통한 회귀 이해\n",
    "\n",
    "> **단순 선형 회귀란**\n",
    "- 독립변수(X)와 종속변수(y)가 하나인 선형 회귀를 의미\n",
    "- 부모님의 키에 따라 자녀의 키가 결정된다고 가정할 때, 부모의 키가 클수록 유전적 영향에 의해 자녀의 키가 커지는 경향을 확인 할 수 있는데 이는 선형 관계로 표현 할 수 있다\n",
    "![](./회귀_단순선형회귀.png)\n",
    "\n",
    "> **머신러닝 회귀 알고리즘**\n",
    "- 데이터를 계속 학습 하면서 비용 함수(손실함수_Log Function)가 반환하는 값(오류 값)을 지속해서 감소시키고 최종적으로 더 이상 감소하지 않는 최소의 오류 값을 구하는것\n",
    "- 최적의 회귀 모델을 만든다는 것은 바로 전체 데이터의 잔차(오류 값)합이 최소가 되는 모델을 만든다는 의미\n",
    "- 동시에 오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다는 의미도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa700e",
   "metadata": {},
   "source": [
    "# 3. 최적의 회귀 모델 생성 방법\n",
    "- 잔차의 합이 최소가 되는 선형식 도출을 의미\n",
    "- 즉 최적의 회귀 계수를 찾는 것\n",
    "\n",
    "> **RSS(Residual Sum of Square) 기반의 회귀 오류 측정**\n",
    "\n",
    "RSS(잔차제곱합) : 오류 값의 제곱을 구해서 더하는 방식, 계산의 편리를 위해 RSS 방식으로 오류 합을 구함\n",
    "- RSS를 최소로 하는 회귀 계수(W0, W1)를 학습을 통해 찾는 것이 머신러닝 기반 회귀의 핵심 사항\n",
    "- RSS는 회귀식의 독립변수(X), 종속변수(y)가 중심 변수가 아니라 회귀 계수(w)가 중심 변수\n",
    "![](./회귀_RSS.png)\n",
    "\n",
    "> **회귀의 비용 함수**\n",
    "- 회귀에서 RSS는 비용이며 회귀계수로 구성되는 RSS를 비용 함수라고 함\n",
    "- 회귀 알고리즘은 데이터를 계속 학습면서 이 비용함수가 반환하는 값(오류값)을 지속해서 감소시키기 최종적으로 더이상 감소하지 않는 최소의 오류 값을 구하는 것\n",
    "- 즉 머신러닝 모델에서 계속 학습할지 결정하는 것을 비용함수 혹은 손실함수(LossFunction)이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca62cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
